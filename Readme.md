ğŸ“š Generador AutomÃ¡tico de Cuestionarios Educativos
Sistema para crear evaluaciones acadÃ©micas automÃ¡ticamente a partir de documentos PDF

ğŸŒŸ CaracterÃ­sticas Principales
ğŸ¯ GeneraciÃ³n automÃ¡tica de preguntas (opciÃ³n mÃºltiple, verdadero/falso, abiertas)

ğŸ“„ Procesamiento inteligente de documentos acadÃ©micos en PDF

ğŸ§  Uso de modelos LLM (Ollama) para comprensiÃ³n semÃ¡ntica

ğŸ“Š PersonalizaciÃ³n de tipos y cantidad de preguntas

ğŸ“ ExportaciÃ³n a PDF listo para imprimir

## ğŸ“¦ Requisitos del Sistema

- **Python 3.10+**
- **Ollama instalado localmente**
- **Modelo LLM descargado** (recomendado: `llama3.2:8b`)

---

## ğŸ“‘ Dependencias

### ğŸ”§ Core del Generador
```bash
langchain-community==0.2.1
langchain-core==0.2.2
langchain-ollama==0.1.4
ollama==0.1.11

ğŸ“„ Procesamiento de PDF
unstructured[pdf]==0.13.4
pikepdf==8.15.0
pdfminer.six==20221105

ğŸ“Š Base de Datos Vectorial
chromadb==0.4.24
sentence-transformers==2.7.0

ğŸ–¥ï¸ Interfaz Web
streamlit==1.33.0

ğŸ“ GeneraciÃ³n de PDF
reportlab==4.2.0

ğŸ“¦ Requisitos Adicionales

Python 3.10+

Ollama instalado localmente

Modelo LLM descargado (recomendado: llama3.2:latest)

ğŸš€ InstalaciÃ³n

1ï¸âƒ£ Clona el repositorio:

git clone https://github.com/emilker/EduQuizGen.git

2ï¸âƒ£ Crea y activa un entorno virtual:

python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Instala las dependencias:

pip install -r requirements.txt

4ï¸âƒ£ Descarga el modelo de Ollama:

ollama pull llama3.2:8b

ğŸ–¥ï¸ Uso

Interfaz Web (Recomendado)
streamlit run app.py y listo

O LÃ­nea de Comandos

python main.py documento.pdf --num_preguntas 10 --tema "BiologÃ­a Celular"

ğŸ—ï¸ Estructura del Proyecto

generador-cuestionarios/
â”œâ”€â”€ app.py                # Interfaz web principal
â”œâ”€â”€ main.py               # VersiÃ³n CLI
â”œâ”€â”€ config.py             # ConfiguraciÃ³n global
â”œâ”€â”€ document_processor.py # Procesamiento de PDFs
â”œâ”€â”€ quiz_generator.py     # GeneraciÃ³n de preguntas
â”œâ”€â”€ vector_db.py          # Almacenamiento vectorial
â”œâ”€â”€ requirements.txt      # Dependencias
â””â”€â”€ README.md             # Este archivo

âš™ï¸ ConfiguraciÃ³n
Edita config.py para personalizar:

CONFIG = {
    "MODELO_LLM": "llama3.2:8b",       # Modelo a usar
    "CHUNK_SIZE": 1200,                # TamaÃ±o de fragmentos de texto
    "CHUNK_OVERLAP": 300,              # Solapamiento entre fragmentos
    "MAX_PREGUNTAS": 20,               # MÃ¡ximo de preguntas por cuestionario
    "DB_DIR": "./vector_db"            # Carpeta para bases vectoriales
}


